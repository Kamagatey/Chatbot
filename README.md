# ðŸ¤– ChatBot Local avec Ollama & Gradio

Ce projet est un assistant conversationnel local utilisant [Ollama](https://ollama.com/) pour lâ€™infÃ©rence de modÃ¨les LLM et [Gradio](https://gradio.app/) pour lâ€™interface web.  
Il permet de discuter avec diffÃ©rents modÃ¨les IA en franÃ§ais, tout en sauvegardant lâ€™historique des conversations.

---

## FonctionnalitÃ©s

- **Interface web simple** (Gradio)
- **Choix du modÃ¨le** (configurable dans `models.py`)
- **Sauvegarde automatique** de lâ€™historique de chat
- **Effacement rapide** de lâ€™historique
- **Support du streaming de rÃ©ponses**
- **Tout fonctionne en local** (pas dâ€™envoi de donnÃ©es vers lâ€™extÃ©rieur)

---

## PrÃ©requis

- Python 3.8+
- [Ollama](https://ollama.com/download) installÃ© et lancÃ© sur votre machine
- ModÃ¨les Ollama tÃ©lÃ©chargÃ©s (voir ci-dessous)

---

## Installation

1. **Cloner le dÃ©pÃ´t**  
   ```bash
   git clone https://github.com/kamagatey/Chatbot.git
   cd ChatBot
   ```

2. **Installer les dÃ©pendances Python**  
   ```bash
   pip install gradio ollama
   ```

3. **TÃ©lÃ©charger les modÃ¨les Ollama**  
   Par exemple :
   ```bash
   ollama pull mistral:7b-instruct-q4_K_M
   ollama pull deepseek-coder:1.3b
   ```
   *(PossibilitÃ©s d'ajout de d'autre modele `models.py`)*


## Utilisation

Lancez lâ€™interface web avec :

```bash
python app.py
```

- AccÃ©dez Ã  [http://localhost:7860](http://localhost:7860) dans votre navigateur.
- Choisissez un modÃ¨le, tapez votre message et discutez !
- Cliquez sur **Effacer lâ€™historique** pour repartir de zÃ©ro.

---

## Structure du projet

```
ChatBot/
â”‚
â”œâ”€â”€ app.py              # Lancement de lâ€™interface Gradio
â”œâ”€â”€ chat_logic.py       # Logique de dialogue avec Ollama
â”œâ”€â”€ models.py           # Liste des modÃ¨les disponibles
â”œâ”€â”€ utils.py            # Fonctions utilitaires (sauvegarde, chargement)
â”œâ”€â”€ data/               # Dossiers de sauvegarde des conversations
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## Personnalisation

- **Ajouter un modÃ¨le** :  
  Ajoutez son nom dans la liste `MODELS` du fichier `models.py` et tÃ©lÃ©chargez-le avec `ollama pull`.
---

## Notes

- Les conversations sont sauvegardÃ©es dans le dossier `data/conversations/`.
- Lâ€™historique de la derniÃ¨re session est stockÃ© dans `data/last_session.json`.
- Le projet fonctionne **uniquement en local** pour la confidentialitÃ©.

---

## DÃ©pendances principales

- [Gradio](https://gradio.app/)
- [Ollama Python Client](https://github.com/ollama/ollama-python)

---

## Licence

Projet open-source, Ã  adapter selon vos besoins.
**KAMAGATE YOUSSOUF**
